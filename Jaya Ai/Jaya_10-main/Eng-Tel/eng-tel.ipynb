{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d642d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets sentencepiece --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2d8c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed and wrote 30 valid JSONL lines to eng-tel.jsonl\n"
     ]
    }
   ],
   "source": [
    "# input_file = \"eng-tel.txt\"\n",
    "# output_file = \"eng-tel.jsonl\"\n",
    "\n",
    "# with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#     lines = [line.strip() for line in f if line.strip()]  # skip blank lines\n",
    "\n",
    "# json_data = []\n",
    "# for i in range(0, len(lines) - 1, 2):\n",
    "#     if lines[i].startswith(\"en:\") and lines[i+1].startswith(\"te:\"):\n",
    "#         en = lines[i].replace(\"en:\", \"\").strip()\n",
    "#         te = lines[i+1].replace(\"te:\", \"\").strip()\n",
    "#         json_data.append({\"translation\": {\"en\": en, \"te\": te}})\n",
    "#     else:\n",
    "#         print(f\"⚠️ Skipping malformed pair at lines {i} and {i+1}\")\n",
    "\n",
    "# # Save to JSONL\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     for item in json_data:\n",
    "#         f.write(f\"{item}\\n\")\n",
    "\n",
    "# print(f\"✅ Successfully converted {len(json_data)} sentence pairs to {output_file}\")\n",
    "\n",
    "import json\n",
    "\n",
    "input_file = \"eng-tel.txt\"\n",
    "output_file = \"eng-tel.jsonl\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "json_data = []\n",
    "for i in range(0, len(lines) - 1, 2):\n",
    "    if lines[i].startswith(\"en:\") and lines[i+1].startswith(\"te:\"):\n",
    "        en = lines[i].replace(\"en:\", \"\").strip()\n",
    "        te = lines[i+1].replace(\"te:\", \"\").strip()\n",
    "        json_obj = {\"translation\": {\"en\": en, \"te\": te}}\n",
    "        json_data.append(json_obj)\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped malformed pair at lines {i} and {i+1}\")\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for obj in json_data:\n",
    "        json.dump(obj, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Fixed and wrote {len(json_data)} valid JSONL lines to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4697b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Shashank\\Eng-Tel\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 30 examples [00:00, 2961.59 examples/s]\n",
      "Map: 100%|██████████| 30/30 [00:00<00:00, 1315.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import MBart50TokenizerFast\n",
    "\n",
    "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "tokenizer.tgt_lang = \"te_IN\"\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"eng-tel.jsonl\", split=\"train\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"te\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6aebdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAI SHASHANK\\AppData\\Local\\Temp\\ipykernel_15332\\3580368695.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "c:\\Shashank\\Eng-Tel\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 04:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>8.744100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.913000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Shashank\\Eng-Tel\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3685: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45, training_loss=8.192110866970486, metrics={'train_runtime': 318.1875, 'train_samples_per_second': 0.283, 'train_steps_per_second': 0.141, 'total_flos': 24380209889280.0, 'train_loss': 8.192110866970486, 'epoch': 3.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    MBartForConditionalGeneration,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "import torch\n",
    "\n",
    "# Load pretrained model\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mbart-en-te-checkpoints\",\n",
    "    per_device_train_batch_size=2,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    fp16=torch.cuda.is_available(),  # Only use if you have GPU\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Data collator handles dynamic padding\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e2713b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mbart-en-te-model\\\\tokenizer_config.json',\n",
       " './mbart-en-te-model\\\\special_tokens_map.json',\n",
       " './mbart-en-te-model\\\\sentencepiece.bpe.model',\n",
       " './mbart-en-te-model\\\\added_tokens.json',\n",
       " './mbart-en-te-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./mbart-en-te-model\")\n",
    "tokenizer.save_pretrained(\"./mbart-en-te-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38431fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "# Load fine-tuned model\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"./mbart-en-te-model\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"./mbart-en-te-model\")\n",
    "\n",
    "# Set source and target language codes\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "tgt_lang = \"te_IN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4826f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Shashank\\Eng-Tel\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telugu Translation: నాకు ఒక గొప్ప సామగ్రి ఇంజనీర్ మారింది కోరుకుంటున్నారు.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model_path = \"./mbart-en-te-model\"  # Change if your path is different\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "# Set language codes\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "target_lang = \"te_IN\"\n",
    "\n",
    "def translate_to_telugu(prompt: str) -> str:\n",
    "    # Tokenize the input English sentence\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate output in Telugu\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[target_lang],\n",
    "        max_length=100\n",
    "    )\n",
    "\n",
    "    # Decode the output tokens to Telugu text\n",
    "    telugu_output = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "    return telugu_output\n",
    "\n",
    "# Example usage\n",
    "eng_input = \"I want to become a great software engineer.\"\n",
    "telugu_output = translate_to_telugu(eng_input)\n",
    "print(\"Telugu Translation:\", telugu_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b20683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Telugu: మైక్రోస్ ఏమిటి?\n"
     ]
    }
   ],
   "source": [
    "# English sentence\n",
    "english_sentence = \"\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(english_sentence, return_tensors=\"pt\")\n",
    "\n",
    "# Set decoder start token to Telugu\n",
    "generated_tokens = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang],\n",
    "    max_length=50\n",
    ")\n",
    "\n",
    "# Decode and print\n",
    "telugu_translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "print(\"Translated Telugu:\", telugu_translation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
